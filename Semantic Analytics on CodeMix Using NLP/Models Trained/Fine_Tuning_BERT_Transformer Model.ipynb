{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251dd35a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-YoOTDjs285_",
    "outputId": "a4d270a3-22bd-4c2c-ad34-ec0e55ce6371"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/84.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Cell 1 ‚Äî install\n",
    "!pip install -q transformers datasets accelerate evaluate scikit-learn sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1de124",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "o31WX8sm3YGK",
    "outputId": "b32e5cc7-90d0-4cb4-dada-8e67c221bc79"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-c4fe42cb-8dab-4630-80ee-963203c3af98\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-c4fe42cb-8dab-4630-80ee-963203c3af98\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving tamil_sentiment_full.csv to tamil_sentiment_full.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 ‚Äî upload local file via browser\n",
    "from google.colab import files\n",
    "uploaded = files.upload()   # choose your tamil_sentiment_full.csv from your machine\n",
    "# After upload, file will be in current working directory, e.g. '/content/tamil_sentiment_full.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a687002f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zrbmTapN4KEn",
    "outputId": "bfab0d56-7988-4c2a-e2ea-db39c18dbfd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines: 44161\n",
      "\n",
      "--- first 20 lines ---\n",
      "001: 'Negative\\tEnna da ellam avan seyal  Mari iruku'\n",
      "002: 'Negative\\tThis movei is just like  ellam avan seyal'\n",
      "003: 'Positive\\tPadam vanthathum 13k dislike pottavaga yellam yea da dislike  pannom nu feel pannanum'\n",
      "004: 'Positive\\tNeraya neraya neraya... ... V era level...thala'\n",
      "005: 'Positive\\twow thavala sema mass....padam oru pundaikum aagathu'\n",
      "006: 'Negative\\tAndha 19 k unlike panavangaluku kolandha porakathu'\n",
      "007: 'Positive\\tYaarellam frst like pottutu video paaka start paneenga....hit like'\n",
      "008: 'Positive\\tEthana padam vanthanu SALT AND PEPPER Mattum than..TH√ÉL√Éü§©ü§©'\n",
      "009: 'Positive\\tThala mass  Hvy sprt kerala Surya anna fans'\n",
      "010: 'Negative\\tElam avan jayal movie  remake pa'\n",
      "011: \"Positive\\tDhayavasenju indha padathula mass ila mayiru ila nu yevanum saavadikadheenga.. let him do such roles.. it's healthy!\"\n",
      "012: 'Positive\\tvera lvl.... Thala sammaaaaaaaaaaaaa......Bgm sammaya iruku'\n",
      "013: 'Positive\\tRomba nal aparam ajith ah normal ah pakaran siva oda build up illama tharamana trailer.....'\n",
      "014: 'Positive\\tNirav shah ....  Love u ma dear.....'\n",
      "015: 'Positive\\tPadam hit nu nenaikkuravange like podunge ..... Naan pottutten..'\n",
      "016: 'Negative\\tThevdiya pasangala intha trailer ku enna da kora evlo dislike uh punda mavanungalae'\n",
      "017: 'Negative\\tDislikes podura thevidiya kandara oooooooli pasangala'\n",
      "018: 'Positive\\tNeenga viswasam ah irukkurathukku mathavangala yan asinga paduthuringa....#Thala...Vera level.....'\n",
      "019: 'Positive\\tSuperb thala... By thalapathy fan... Naraya naraya naraya... Vera vera vera 2um sink agudhu....'\n",
      "020: 'Positive\\tLast dialogue  epo ellam may epd than jalra taturaga'\n",
      "\n",
      "--- around line 51 (¬±5) ---\n",
      "046: 'Positive\\tThala and yuvan ..like ha therika vidungada pasangala...bgm vera level ..'\n",
      "047: 'Positive\\tNow you are lying lying lying. Thala mass'\n",
      "048: 'Positive\\tUsure mela poitu varuthu Thala ungala paakum pothu.....'\n",
      "049: 'Positive\\tThala court scene marana mass dialogue delivery super duper hit'\n",
      "050: 'Positive\\tThala  looking  mass'\n",
      "051: 'Positive\\t@0:21 oh man, Thala looking amazing'\n",
      "052: 'Positive\\tThalaaa !!!!!!.....yuvan poramboku ena da bgm potu vechirka'\n",
      "053: 'Positive\\tAdangappa semma tralier fight na innum thrikum ü§óü§óü§ó'\n",
      "054: 'Negative\\tAyioooo mudela da punda yanna detu padom purela da ü§îü§î'\n",
      "055: 'Positive\\tHindi padam trailer patha maari iruku'\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = 'tamil_sentiment_full.csv'   # update if needed\n",
    "\n",
    "# print first 120 lines and lines around line 51\n",
    "with open(DATA_PATH, 'r', encoding='utf-8', errors='replace') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "print(\"Total lines:\", len(lines))\n",
    "print(\"\\n--- first 20 lines ---\")\n",
    "for i, line in enumerate(lines[:20], 1):\n",
    "    print(f\"{i:03d}: {line.rstrip()!r}\")\n",
    "\n",
    "print(\"\\n--- around line 51 (¬±5) ---\")\n",
    "start = max(0, 50-5)   # zero-indexed\n",
    "for i in range(start, min(len(lines), 50+5)):\n",
    "    print(f\"{i+1:03d}: {lines[i].rstrip()!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56321959",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "PkgV9BdW5QOZ",
    "outputId": "7d09f3ae-a025-43c6-f1f7-51aa193cb77e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned rows: 44020  |  Malformed (no tab) lines: 0\n",
      "\n",
      "Sample rows:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"print(f\\\"\\\\nSaved cleaned CSV -> {CLEAN_PATH}\\\")\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Positive\",\n          \"Negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"This movei is just like  ellam avan seyal\",\n          \"Andha 19 k unlike panavangaluku kolandha porakathu\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-8f890f9a-a747-4d84-a8df-c82132307704\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Enna da ellam avan seyal  Mari iruku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>This movei is just like  ellam avan seyal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Padam vanthathum 13k dislike pottavaga yellam ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Neraya neraya neraya... ... V era level...thala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>wow thavala sema mass....padam oru pundaikum a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Andha 19 k unlike panavangaluku kolandha porak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Yaarellam frst like pottutu video paaka start ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Ethana padam vanthanu SALT AND PEPPER Mattum t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f890f9a-a747-4d84-a8df-c82132307704')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-8f890f9a-a747-4d84-a8df-c82132307704 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-8f890f9a-a747-4d84-a8df-c82132307704');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-f308f713-48ae-465c-b4ea-01623143ba2c\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f308f713-48ae-465c-b4ea-01623143ba2c')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-f308f713-48ae-465c-b4ea-01623143ba2c button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0  Negative               Enna da ellam avan seyal  Mari iruku\n",
       "1  Negative          This movei is just like  ellam avan seyal\n",
       "2  Positive  Padam vanthathum 13k dislike pottavaga yellam ...\n",
       "3  Positive    Neraya neraya neraya... ... V era level...thala\n",
       "4  Positive  wow thavala sema mass....padam oru pundaikum a...\n",
       "5  Negative  Andha 19 k unlike panavangaluku kolandha porak...\n",
       "6  Positive  Yaarellam frst like pottutu video paaka start ...\n",
       "7  Positive  Ethana padam vanthanu SALT AND PEPPER Mattum t..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label distribution:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>24873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unknown_state</th>\n",
       "      <td>6904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>5228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixed_feelings</th>\n",
       "      <td>4928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not-Tamil</th>\n",
       "      <td>2087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ],
      "text/plain": [
       "label\n",
       "Positive          24873\n",
       "unknown_state      6904\n",
       "Negative           5228\n",
       "Mixed_feelings     4928\n",
       "not-Tamil          2087\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved cleaned CSV -> tamil_sentiment_full.cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Clean tab-quoted file and produce a tidy CSV for training\n",
    "DATA_PATH = 'tamil_sentiment_full.csv'   # your uploaded file\n",
    "CLEAN_PATH = 'tamil_sentiment_full.cleaned.csv'\n",
    "\n",
    "rows = []\n",
    "bad_lines = []\n",
    "with open(DATA_PATH, 'r', encoding='utf-8', errors='replace') as f:\n",
    "    for i, raw in enumerate(f, 1):\n",
    "        line = raw.rstrip('\\n').rstrip('\\r')\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        # remove a single leading and trailing single-quote if present\n",
    "        if line.startswith(\"'\") and line.endswith(\"'\"):\n",
    "            line = line[1:-1]\n",
    "        # split on the first tab into label and text\n",
    "        if '\\t' in line:\n",
    "            label, text = line.split('\\t', 1)\n",
    "            rows.append((label.strip(), text.strip()))\n",
    "        else:\n",
    "            # keep track of malformed lines\n",
    "            bad_lines.append((i, line))\n",
    "\n",
    "# Build DataFrame\n",
    "import pandas as pd\n",
    "clean_df = pd.DataFrame(rows, columns=['label', 'text'])\n",
    "print(f\"Cleaned rows: {len(clean_df)}  |  Malformed (no tab) lines: {len(bad_lines)}\")\n",
    "\n",
    "# Show a few malformed lines (if any) so you can inspect\n",
    "if bad_lines:\n",
    "    print(\"\\nSample malformed lines (line_no, content):\")\n",
    "    for ln, content in bad_lines[:10]:\n",
    "        print(ln, repr(content))\n",
    "\n",
    "# Basic sanity checks\n",
    "print(\"\\nSample rows:\")\n",
    "display(clean_df.head(8))\n",
    "print(\"\\nLabel distribution:\")\n",
    "display(clean_df['label'].value_counts())\n",
    "\n",
    "# Save cleaned CSV (comma-separated). If you prefer TSV, change sep='\\t'\n",
    "clean_df.to_csv(CLEAN_PATH, index=False, encoding='utf-8')\n",
    "print(f\"\\nSaved cleaned CSV -> {CLEAN_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fd3fb8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "1bee1478b97e40b1a28b09247ae34701",
      "70a475d425f34150a4668d4cf36a81ad",
      "12c9572d4a5b49309799cfa858b0ba5c",
      "ca8991cb3a3245718e5631a9ef13638d",
      "3fc60a6ca81d48f199274347a2b97115",
      "46eba43310e84c10b8e80b3e878ed6aa",
      "2f0cc0629ac64be28c5f3a915f54e70b",
      "5ba48a3a29304001a41d74e7e398deee",
      "2fb5ee0029a24368abfcd646312660c9",
      "72ebb74a61544efe9a831b6d0beeb9b0",
      "59239b05732e4e2eaf60d3fa297f420d",
      "16f6ebb0b28847ee96ff0d486171c6d1",
      "f46a690ccf2744bc94eab9785f2ddb1a",
      "9b0dc27a2a6c4f0db3b88af39ae5eedf",
      "68b4becd53444c74928954084719732f",
      "fbf8689b5184441d9fbd12ed1d71246d",
      "f7fe85c3b3714a778fed74d83872b55e",
      "4c947e204ce8401d95407c0b403d0e56",
      "cdbd2c3c226c489284d6a6510a424520",
      "08f86b6c492b4364a6f70351b0b657dd",
      "2d8ed7e231794445a51921c4814d82af",
      "c29b86e2abcf4324b7d6d44211b97d05",
      "cf56a0041e64486193ae9de847d84925",
      "6066ffd707c548d4b3c4245926df29a4",
      "2431155c149b4137af96cd8dc89d8996",
      "0029ee97bd1b4371b91b3dd26e5a4bdf",
      "9ba80b4a01754a6f8fba6daaa5f8aa7e",
      "821b1e81f39341de946debb9b51d36a7",
      "7c299d5e9b2549448004d11c9ea42022",
      "0ba996f02b5c4b769b8750d568b6de12",
      "b459e6e6b2d8492b86f4bf3687580ae8",
      "30fe3cceb0d944a196e4d368921bff0f",
      "65780497c0e149248c54114b0f4bea80",
      "cf680d31851a4b3ab7aaebca3dbf7cb5",
      "36b3860d26244c92ba0d752b2fadafd9",
      "8f95942e5f864b6eab95fb21a0eba2bc",
      "5ea6400bf69841fa879b608778cf5a11",
      "32442640f7fb4f3cbbaee289e479fca8",
      "9acd436a2dcc49288b40ce453e9de795",
      "eb88dadc79654c5e9c1d6d50c0e9189b",
      "5b9d94d6566e433fb433953af2ebcd25",
      "6f54efcfed9c4beaa3e591408f2700a4",
      "e7c710da41cd400a9b31539731558a2f",
      "cfb87387b3394d179fe10c734c683945",
      "2adb258a9de54bf2a0fd1f00098d43a4",
      "ba6c3a396149438cb83296c2abc629c0",
      "73d9dfa439be4c1399031c9c7356f62b",
      "2255e93c2fdb448892f7ba6106ab233f",
      "00cf8bb69bf84cb38e3b4d10292ae1c2",
      "93c15800768545e4b4f537f637adbfc7",
      "100f511bb5ca4468b276c53647f23656",
      "4424ba96150f4efeb673d64e4bfb989e",
      "dae798a7cc204c32a10f05c9befcb148",
      "068db857ac9940f7a1c6eb9b8114b1aa",
      "e10e3755696942949c7dc17a71112b74",
      "60243d4b6e1c4e7dbe1db2c722159f00",
      "e8a90d46a6b642e483c6b4107bd32536",
      "08c457f192e1480eb12deceaf68c4045",
      "d37141e6963e4e14b7e33c2e756ff324",
      "8eebe25d7a2848a4beec2fa90f6f88f1",
      "e4720e291b4449ccaca851ffce92f5a5",
      "ea4713c7997640ecbef0d64f358e0e2b",
      "ebca7a3ae1be46569f6e6508bae791d2",
      "80947090f9e6465b9645ff1204639f39",
      "f423fbeab8d9412090d4a3fe53a09c35",
      "55b2155dd33441628623abb1e72675c8",
      "442437b1819041f59d933faf44f87e22",
      "ba7b1d51bace453cacdad02bc75f3f9f",
      "ae5e27693a6648d7b90673fc93c5848f",
      "32f344c5726d44408659d7b0a3cb944c",
      "73d5ea2ee8624e7f8c8e22c24ccf8304",
      "8c238cabdace45d380da5193530ec2e3",
      "9bc5abff23be40459ba8effee9bc885c",
      "a29f820a78c14724b5d7f45a88e6d0ad",
      "1db5373b3e114be4b4fa01c94bc8396e",
      "494a3774d81e458f940ca0aa74135bcf",
      "97bc45c694b34260b48ea771d10815c4",
      "af44adca30dc46fcbc5d724a30b872f3",
      "f18dccb97b644951998ec3498261a1d6",
      "ddcbd69d943f4a8fb8fb69bfe153514e",
      "863cc0a57826481b9be311401ef4779b",
      "0f0cf2abb74d443aa8a25e15d3581248",
      "62811d0fa9de4bd784f8cee6d2c3ee25",
      "18003a8d8e2247bc9d242a79e7e11dad",
      "f1b67f11629f445ca4be8d1bae893789",
      "b62b5dd4fa4240ed8d799c9a824d4459",
      "20808b09544544b1985e3dbda39bbf76",
      "178c1be3302f41f9b801606cce3249ca",
      "95251da47d264b388ceb4469ff709ef1",
      "54a6876088c541448a1ed6b5484add74",
      "315aa34a399a4d2aa493bd9d5d9f1a9d",
      "7481415d919e4837982f687429b820df",
      "3ddd035476e142be909f08e798ec29dc",
      "2cf8fab229c147998f1dd88626967cce",
      "ca78c268244046718672b1be940160e9",
      "de5a5002664a4673b355ef6d36547586",
      "e9f1b39c86bd4f7e89393754f0c9fef2",
      "02cc0637e18b4e72a0f45af5f86d5755",
      "786bce1acdbb423bac308c30778f6357",
      "dc40b7019bad4ef6bc3ec244a866c396",
      "a984f9c0b6bc4c55b473eee452a82e86",
      "653c87b370ef46a7ac5017e7348f6ccb",
      "d594d80ecfb54a71988eca1c87d5dae2",
      "8eadba70a9834503baaa7af6285a636e",
      "4b6c3be5357e40edbe5ba2018be3e9c2",
      "ed8771212d4841d09e1babb13165e5b6",
      "24bec585d3684dc98407e54e4491655d",
      "8275ae7f26e94f60b7010d7c0447e80a",
      "5b2010bb673f45ef958a807381a75011",
      "14c05f1da62041af80881cf5de97f099",
      "a137abca685f4344b9511f39c2d844f6",
      "dc1cdd349876453da154c300d88b208d",
      "5bb696ea615143018664030d28a1d702",
      "8b03ef12aeb049d08d9eab88b81a4359",
      "e841bfa080bf42a4af083d2ff8cd2a3f",
      "73ac25b8fd404f5a91369b9d5c787bdd",
      "aee7b0f7543d465bb3905836f909f305",
      "267cf976df1345c4a78de07a88512466",
      "4629fbea0d3143e2be07ae30dcbcfd72",
      "455afc0e159b4f1eb0549c94bb04883a",
      "04ce383d733b48eb80148457eb13a985",
      "d0a398fd8a2f478e96109a577429fcd8",
      "5433c4268b1047b0aeca457cdef2d6ad",
      "8bacf1284bba47858710f30e9461f627",
      "a23d3939216d4f39a76b910f0b476cab",
      "5561571152994d88908862e2ec2f31c0",
      "6420b32b20f442e2afc33e89c7a4a567",
      "203829784d51481b9ccea4e06ea0d3c7",
      "be882d804c7e4415b57cc03cc9245790",
      "dd7cda1e001e4b8a903eeb0b4932e744",
      "a2636ba8a0214de58c4b4180afeffe74",
      "d06b1b879e4d4565bc9f4ae0aeae83c6",
      "2e39635601a14c07b0eeff95c94f6472",
      "bfb9eba17085430e8bf0f6380cae94ae",
      "3f362c0b12b74739bb8a3113cf79ffb6",
      "2c114d08888741cda54723168b69c91b",
      "1d13b1dd7fd34af388687d20d4fa451d",
      "3b8e62fbcbf54437842187792382db31",
      "7dd6bdf437284670b91bcaf803e8ee69",
      "ade1fa1d372642798025f7d39e6325bb",
      "8675dab3a0ad433287ffde09e84a1b53",
      "175e9e2eed9d4456803a4a33c7068384",
      "7356b484f99e4721aee35fbfe0603e53"
     ]
    },
    "id": "gn8TSs9O6Iwy",
    "outputId": "e36f6355-9a88-45a5-8735-977230dd81a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes (id->label): [(0, 'Mixed_feelings'), (1, 'Negative'), (2, 'Positive'), (3, 'not-Tamil'), (4, 'unknown_state')]\n",
      "Train / Test sizes: 35216 8804\n",
      "Class weights: [1.78670726 1.68417025 0.35394743 4.21748503 1.27524896]\n",
      "\n",
      "=== TRAINING mBERT (bert-base-multilingual-cased) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bee1478b97e40b1a28b09247ae34701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35216 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f6ebb0b28847ee96ff0d486171c6d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8804 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11005' max='11005' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11005/11005 27:03, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.237200</td>\n",
       "      <td>1.188092</td>\n",
       "      <td>0.440282</td>\n",
       "      <td>0.519260</td>\n",
       "      <td>0.458536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.126400</td>\n",
       "      <td>1.162655</td>\n",
       "      <td>0.454950</td>\n",
       "      <td>0.529694</td>\n",
       "      <td>0.470627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.009300</td>\n",
       "      <td>1.203580</td>\n",
       "      <td>0.475564</td>\n",
       "      <td>0.533136</td>\n",
       "      <td>0.490592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.861900</td>\n",
       "      <td>1.292437</td>\n",
       "      <td>0.477112</td>\n",
       "      <td>0.527379</td>\n",
       "      <td>0.482648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.710300</td>\n",
       "      <td>1.394825</td>\n",
       "      <td>0.473898</td>\n",
       "      <td>0.524445</td>\n",
       "      <td>0.489802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval (macro metrics): {'eval_loss': 1.2035801410675049, 'eval_precision': 0.4755641503192688, 'eval_recall': 0.533136497486879, 'eval_f1': 0.4905923777718984, 'eval_runtime': 13.1546, 'eval_samples_per_second': 669.269, 'eval_steps_per_second': 41.886}\n",
      "\n",
      "Classification report for mBERT:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Mixed_feelings     0.2490    0.4331    0.3162       986\n",
      "      Negative     0.3885    0.4465    0.4155      1046\n",
      "      Positive     0.8441    0.5965    0.6990      4974\n",
      "     not-Tamil     0.5054    0.6763    0.5785       417\n",
      " unknown_state     0.3908    0.5134    0.4438      1381\n",
      "\n",
      "      accuracy                         0.5511      8804\n",
      "     macro avg     0.4756    0.5331    0.4906      8804\n",
      "  weighted avg     0.6362    0.5511    0.5767      8804\n",
      "\n",
      "Saved artifacts to ./bert_models/mBERT\n",
      "\n",
      "=== TRAINING MuRIL (google/muril-base-cased) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/muril-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf56a0041e64486193ae9de847d84925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35216 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf680d31851a4b3ab7aaebca3dbf7cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8804 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11005' max='11005' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11005/11005 30:52, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.281900</td>\n",
       "      <td>1.251731</td>\n",
       "      <td>0.439326</td>\n",
       "      <td>0.489737</td>\n",
       "      <td>0.452495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.178700</td>\n",
       "      <td>1.167046</td>\n",
       "      <td>0.449414</td>\n",
       "      <td>0.528049</td>\n",
       "      <td>0.466251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.073100</td>\n",
       "      <td>1.165188</td>\n",
       "      <td>0.479841</td>\n",
       "      <td>0.547958</td>\n",
       "      <td>0.501697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.942900</td>\n",
       "      <td>1.218890</td>\n",
       "      <td>0.482250</td>\n",
       "      <td>0.548923</td>\n",
       "      <td>0.499156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.808200</td>\n",
       "      <td>1.270329</td>\n",
       "      <td>0.499176</td>\n",
       "      <td>0.548663</td>\n",
       "      <td>0.515357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval (macro metrics): {'eval_loss': 1.2703287601470947, 'eval_precision': 0.49917624428446816, 'eval_recall': 0.548662615270271, 'eval_f1': 0.5153571331190253, 'eval_runtime': 10.3214, 'eval_samples_per_second': 852.985, 'eval_steps_per_second': 53.384}\n",
      "\n",
      "Classification report for MuRIL:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Mixed_feelings     0.2612    0.3905    0.3130       986\n",
      "      Negative     0.4395    0.4723    0.4553      1046\n",
      "      Positive     0.8312    0.6425    0.7248      4974\n",
      "     not-Tamil     0.5585    0.6978    0.6205       417\n",
      " unknown_state     0.4054    0.5402    0.4632      1381\n",
      "\n",
      "      accuracy                         0.5806      8804\n",
      "     macro avg     0.4992    0.5487    0.5154      8804\n",
      "  weighted avg     0.6411    0.5806    0.6007      8804\n",
      "\n",
      "Saved artifacts to ./bert_models/MuRIL\n",
      "\n",
      "=== TRAINING IndicBERT (ai4bharat/indic-bert) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2adb258a9de54bf2a0fd1f00098d43a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35216 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60243d4b6e1c4e7dbe1db2c722159f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8804 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11005' max='11005' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11005/11005 13:56, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.267500</td>\n",
       "      <td>1.251445</td>\n",
       "      <td>0.433247</td>\n",
       "      <td>0.484975</td>\n",
       "      <td>0.427018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.192600</td>\n",
       "      <td>1.207057</td>\n",
       "      <td>0.446312</td>\n",
       "      <td>0.511822</td>\n",
       "      <td>0.442486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.087400</td>\n",
       "      <td>1.216555</td>\n",
       "      <td>0.452779</td>\n",
       "      <td>0.513040</td>\n",
       "      <td>0.469130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.932500</td>\n",
       "      <td>1.279472</td>\n",
       "      <td>0.450930</td>\n",
       "      <td>0.509117</td>\n",
       "      <td>0.462730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.743700</td>\n",
       "      <td>1.378282</td>\n",
       "      <td>0.448772</td>\n",
       "      <td>0.500579</td>\n",
       "      <td>0.464173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval (macro metrics): {'eval_loss': 1.216555118560791, 'eval_precision': 0.45277938004513996, 'eval_recall': 0.5130401133454611, 'eval_f1': 0.46913039312760957, 'eval_runtime': 10.7191, 'eval_samples_per_second': 821.34, 'eval_steps_per_second': 51.404}\n",
      "\n",
      "Classification report for IndicBERT:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Mixed_feelings     0.2443    0.4118    0.3066       986\n",
      "      Negative     0.3498    0.3920    0.3697      1046\n",
      "      Positive     0.8239    0.5899    0.6875      4974\n",
      "     not-Tamil     0.4612    0.6691    0.5460       417\n",
      " unknown_state     0.3847    0.5025    0.4358      1381\n",
      "\n",
      "      accuracy                         0.5365      8804\n",
      "     macro avg     0.4528    0.5130    0.4691      8804\n",
      "  weighted avg     0.6166    0.5365    0.5609      8804\n",
      "\n",
      "Saved artifacts to ./bert_models/IndicBERT\n",
      "\n",
      "=== TRAINING XLM-R (xlm-roberta-base) ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442437b1819041f59d933faf44f87e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af44adca30dc46fcbc5d724a30b872f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95251da47d264b388ceb4469ff709ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc40b7019bad4ef6bc3ec244a866c396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a137abca685f4344b9511f39c2d844f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a398fd8a2f478e96109a577429fcd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35216 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e39635601a14c07b0eeff95c94f6472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8804 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11005' max='11005' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11005/11005 34:11, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.248200</td>\n",
       "      <td>1.240818</td>\n",
       "      <td>0.476665</td>\n",
       "      <td>0.495810</td>\n",
       "      <td>0.451732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.152600</td>\n",
       "      <td>1.198082</td>\n",
       "      <td>0.448077</td>\n",
       "      <td>0.535034</td>\n",
       "      <td>0.450798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.103500</td>\n",
       "      <td>1.188108</td>\n",
       "      <td>0.483497</td>\n",
       "      <td>0.535248</td>\n",
       "      <td>0.496976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.990700</td>\n",
       "      <td>1.234576</td>\n",
       "      <td>0.480192</td>\n",
       "      <td>0.535457</td>\n",
       "      <td>0.487824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.889900</td>\n",
       "      <td>1.263428</td>\n",
       "      <td>0.486389</td>\n",
       "      <td>0.545547</td>\n",
       "      <td>0.502330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval (macro metrics): {'eval_loss': 1.2634284496307373, 'eval_precision': 0.48638940237402545, 'eval_recall': 0.5455467549822048, 'eval_f1': 0.5023300190021518, 'eval_runtime': 10.4661, 'eval_samples_per_second': 841.189, 'eval_steps_per_second': 52.646}\n",
      "\n",
      "Classification report for XLM-R:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Mixed_feelings     0.2555    0.4097    0.3148       986\n",
      "      Negative     0.3756    0.5210    0.4365      1046\n",
      "      Positive     0.8511    0.5919    0.6982      4974\n",
      "     not-Tamil     0.5442    0.6787    0.6041       417\n",
      " unknown_state     0.4055    0.5264    0.4581      1381\n",
      "\n",
      "      accuracy                         0.5569      8804\n",
      "     macro avg     0.4864    0.5455    0.5023      8804\n",
      "  weighted avg     0.6435    0.5569    0.5821      8804\n",
      "\n",
      "Saved artifacts to ./bert_models/XLM-R\n",
      "\n",
      "Model comparison (macro metrics):\n",
      "       model                      model_id  precision    recall        f1\n",
      "0      MuRIL       google/muril-base-cased   0.499176  0.548663  0.515357\n",
      "1      XLM-R              xlm-roberta-base   0.486389  0.545547  0.502330\n",
      "2      mBERT  bert-base-multilingual-cased   0.475564  0.533136  0.490592\n",
      "3  IndicBERT          ai4bharat/indic-bert   0.452779  0.513040  0.469130\n",
      "\n",
      "Saved model_comparison_results_weighted.csv and model outputs under ./bert_models\n"
     ]
    }
   ],
   "source": [
    "# BERT-family training pipeline (mBERT, MuRIL, IndicBERT, XLM-R) ‚Äî 5 epochs, class-weighted\n",
    "# Requirements (run once): !pip install -q transformers datasets accelerate evaluate scikit-learn sentencepiece\n",
    "\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"   # disable W&B prompt\n",
    "\n",
    "import random, numpy as np, pandas as pd, torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import evaluate\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    Trainer, TrainingArguments, DataCollatorWithPadding\n",
    ")\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "DATA_PATH = 'tamil_sentiment_full.cleaned.csv'   # ensure this file is uploaded in Colab\n",
    "MODEL_IDS = {\n",
    "    'mBERT': 'bert-base-multilingual-cased',\n",
    "    'MuRIL': 'google/muril-base-cased',\n",
    "    'IndicBERT': 'ai4bharat/indic-bert',\n",
    "    'XLM-R': 'xlm-roberta-base'\n",
    "}\n",
    "OUTPUT_DIR = './bert_models'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "EPOCHS = 5                # <--- you requested at least 5 epochs\n",
    "BATCH_SIZE = 16           # reduce if OOM (8 or 4)\n",
    "LR = 2e-5\n",
    "MAX_LENGTH = 256          # reduce to 128 if OOM\n",
    "FP16 = True if torch.cuda.is_available() else False\n",
    "GRAD_ACCUM = 1\n",
    "# ----------------------------\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(DATA_PATH, encoding='utf-8')\n",
    "assert 'text' in df.columns and 'label' in df.columns, \"CSV must contain 'text' and 'label' columns\"\n",
    "df['text'] = df['text'].astype(str)\n",
    "\n",
    "# Label encode\n",
    "le = LabelEncoder()\n",
    "df['label_enc'] = le.fit_transform(df['label'])\n",
    "num_labels = len(le.classes_)\n",
    "print(\"Classes (id->label):\", list(enumerate(le.classes_)))\n",
    "\n",
    "# Train/test split (stratified)\n",
    "train_df, test_df = train_test_split(df[['text','label_enc']], test_size=0.2, random_state=SEED, stratify=df['label_enc'])\n",
    "train_df = train_df.reset_index(drop=True); test_df = test_df.reset_index(drop=True)\n",
    "print(\"Train / Test sizes:\", len(train_df), len(test_df))\n",
    "\n",
    "# Compute class weights (balanced)\n",
    "class_weights_np = compute_class_weight(class_weight='balanced', classes=np.unique(train_df['label_enc']), y=train_df['label_enc'])\n",
    "class_weights_tensor = torch.tensor(class_weights_np, dtype=torch.float)\n",
    "print(\"Class weights:\", class_weights_np)\n",
    "\n",
    "# Prepare metrics\n",
    "metric_precision = evaluate.load('precision')\n",
    "metric_recall = evaluate.load('recall')\n",
    "metric_f1 = evaluate.load('f1')\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "    if isinstance(logits, tuple): logits = logits[0]\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    p = metric_precision.compute(predictions=preds, references=labels, average='macro')['precision']\n",
    "    r = metric_recall.compute(predictions=preds, references=labels, average='macro')['recall']\n",
    "    f = metric_f1.compute(predictions=preds, references=labels, average='macro')['f1']\n",
    "    return {'precision': p, 'recall': r, 'f1': f}\n",
    "\n",
    "# Custom Trainer to inject class weights; accept arbitrary kwargs to be compatible\n",
    "from transformers import Trainer as HfTrainer\n",
    "class WeightedTrainer(HfTrainer):\n",
    "    def __init__(self, class_weights_tensor=None, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights_tensor = class_weights_tensor\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        inputs_for_model = {k:v for k,v in inputs.items() if k != \"labels\"}\n",
    "        outputs = model(**inputs_for_model)\n",
    "        logits = outputs.logits if hasattr(outputs, 'logits') else outputs[0]\n",
    "        weight = self.class_weights_tensor.to(logits.device).to(logits.dtype) if self.class_weights_tensor is not None else None\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=weight)\n",
    "        loss = loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "results = []\n",
    "\n",
    "for short_name, model_id in MODEL_IDS.items():\n",
    "    print(f\"\\n=== TRAINING {short_name} ({model_id}) ===\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=num_labels)\n",
    "\n",
    "    # Prepare datasets\n",
    "    ds_train = Dataset.from_pandas(train_df.rename(columns={'label_enc':'label'}))\n",
    "    ds_test = Dataset.from_pandas(test_df.rename(columns={'label_enc':'label'}))\n",
    "\n",
    "    def preprocess(examples):\n",
    "        return tokenizer(examples['text'], truncation=True, padding=False, max_length=MAX_LENGTH)\n",
    "    ds_train = ds_train.map(preprocess, batched=True)\n",
    "    ds_test = ds_test.map(preprocess, batched=True)\n",
    "\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    model_output = os.path.join(OUTPUT_DIR, short_name)\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=model_output,\n",
    "        eval_strategy='epoch',\n",
    "        save_strategy='epoch',\n",
    "        learning_rate=LR,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        num_train_epochs=EPOCHS,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='f1',\n",
    "        seed=SEED,\n",
    "        logging_steps=200,\n",
    "        fp16=FP16,\n",
    "        gradient_accumulation_steps=GRAD_ACCUM,\n",
    "        save_total_limit=2,\n",
    "        report_to=[]      # disables W&B / trackers\n",
    "    )\n",
    "\n",
    "    trainer = WeightedTrainer(\n",
    "        class_weights_tensor=class_weights_tensor,\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=ds_train,\n",
    "        eval_dataset=ds_test,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate\n",
    "    eval_res = trainer.evaluate(eval_dataset=ds_test)\n",
    "    print('Eval (macro metrics):', {k:v for k,v in eval_res.items() if k.startswith('eval_')})\n",
    "\n",
    "    # Predict for classification report / confusion matrix\n",
    "    preds_output = trainer.predict(ds_test)\n",
    "    logits = preds_output.predictions\n",
    "    if isinstance(logits, tuple): logits = logits[0]\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    labels = preds_output.label_ids\n",
    "\n",
    "    report = classification_report(labels, preds, target_names=le.classes_, digits=4, zero_division=0)\n",
    "    print(f\"\\nClassification report for {short_name}:\\n{report}\")\n",
    "    cm = confusion_matrix(labels, preds, normalize='true')\n",
    "    np.savetxt(os.path.join(model_output, 'confusion_matrix_norm.csv'), cm, delimiter=',')\n",
    "    with open(os.path.join(model_output, 'classification_report.txt'), 'w', encoding='utf-8') as fh:\n",
    "        fh.write(report)\n",
    "\n",
    "    results.append({\n",
    "        'model': short_name,\n",
    "        'model_id': model_id,\n",
    "        'precision': float(eval_res.get('eval_precision', np.nan)),\n",
    "        'recall': float(eval_res.get('eval_recall', np.nan)),\n",
    "        'f1': float(eval_res.get('eval_f1', np.nan))\n",
    "    })\n",
    "\n",
    "    print(f\"Saved artifacts to {model_output}\")\n",
    "\n",
    "# Summarize\n",
    "results_df = pd.DataFrame(results).sort_values('f1', ascending=False).reset_index(drop=True)\n",
    "results_df.to_csv('model_comparison_results_weighted.csv', index=False)\n",
    "print(\"\\nModel comparison (macro metrics):\")\n",
    "print(results_df)\n",
    "print(\"\\nSaved model_comparison_results_weighted.csv and model outputs under\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62887d97",
   "metadata": {
    "id": "ZbTMbYFsfiML"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
